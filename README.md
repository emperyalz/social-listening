# Social Listening Platform

Real Estate Competitor Intelligence Dashboard - Track and analyze competitor social media performance across Instagram, TikTok, and YouTube.

## Features

- ğŸ“Š **Dashboard** - Overview of all tracked competitors with key metrics
- ğŸ‘¥ **Competitor Management** - Add/remove competitor accounts by platform and market
- ğŸ“ˆ **Insights** - Content patterns, best posting times, top hashtags
- ğŸ“ **Posts** - Browse and analyze competitor content
- ğŸŒ **Markets** - Geographic segmentation (Panama City, CDMX, Bogota, etc.)
- âš¡ **Automated Scraping** - Daily data collection via Vercel Cron

## Tech Stack

- **Frontend**: Next.js 14, React, Tailwind CSS
- **Backend**: Convex (real-time database + serverless functions)
- **Scraping**: Apify actors for Instagram, TikTok, YouTube
- **Hosting**: Vercel
- **Cron Jobs**: Vercel Cron for daily automated scraping

## Setup Instructions

### 1. Clone and Install

```bash
git clone <your-repo-url>
cd social-listening
npm install
```

### 2. Environment Variables

Create a `.env.local` file with:

```env
# Convex
CONVEX_DEPLOYMENT=dev:usable-bird-579
NEXT_PUBLIC_CONVEX_URL=https://usable-bird-579.convex.cloud

# Apify
APIFY_API_TOKEN=your_apify_token_here

# YouTube Data API
YOUTUBE_API_KEY=your_youtube_api_key_here

# Cron Secret (generate a random string)
CRON_SECRET=your_random_secret_here
```

### 3. Initialize Convex

```bash
npx convex dev
```

This will:
- Connect to your Convex project
- Deploy the schema and functions
- Start the development sync

### 4. Seed Initial Markets

Once Convex is running, go to the Markets page in the app and click "Seed Default Markets" to add:
- Panama City, Panama
- CDMX, Mexico
- Bogota, Colombia
- Medellin, Colombia
- Los Angeles, USA
- New York City, USA
- Miami, USA

### 5. Add Competitor Accounts

Go to the Competitors page and add accounts to track:

1. Select Platform (Instagram, TikTok, or YouTube)
2. Enter username
3. Select market
4. Optionally add company name
5. Select account type (brokerage, individual broker, developer, other)

### 6. Run Your First Scrape

Go to the Jobs page and click "Run [Platform] Scrape" for each platform to collect initial data.

## Deployment to Vercel

### 1. Create GitHub Repository

```bash
git init
git add .
git commit -m "Initial commit"
git remote add origin https://github.com/your-username/social-listening.git
git push -u origin main
```

### 2. Deploy to Vercel

1. Go to [vercel.com](https://vercel.com)
2. Click "Add New Project"
3. Import your GitHub repository
4. Add environment variables:
   - `CONVEX_DEPLOYMENT`
   - `NEXT_PUBLIC_CONVEX_URL`
   - `APIFY_API_TOKEN`
   - `YOUTUBE_API_KEY`
   - `CRON_SECRET`
5. Deploy!

### 3. Configure Convex for Production

```bash
npx convex deploy
```

This deploys your Convex functions to production.

### 4. Set Environment Variables in Convex

Go to your Convex dashboard and add:
- `APIFY_API_TOKEN`
- `YOUTUBE_API_KEY`
- `CRON_SECRET`

## Project Structure

```
social-listening/
â”œâ”€â”€ convex/
â”‚   â”œâ”€â”€ schema.ts          # Database schema
â”‚   â”œâ”€â”€ accounts.ts        # Account management
â”‚   â”œâ”€â”€ markets.ts         # Market management
â”‚   â”œâ”€â”€ posts.ts           # Post queries
â”‚   â”œâ”€â”€ scraping.ts        # Apify integration
â”‚   â”œâ”€â”€ ingestion.ts       # Data processing
â”‚   â”œâ”€â”€ insights.ts        # Analytics queries
â”‚   â””â”€â”€ http.ts            # HTTP endpoints
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ dashboard/     # Main dashboard
â”‚   â”‚   â”œâ”€â”€ competitors/   # Competitor management
â”‚   â”‚   â”œâ”€â”€ insights/      # Analytics page
â”‚   â”‚   â”œâ”€â”€ posts/         # Post browser
â”‚   â”‚   â”œâ”€â”€ markets/       # Market management
â”‚   â”‚   â”œâ”€â”€ jobs/          # Scraping jobs
â”‚   â”‚   â”œâ”€â”€ settings/      # Configuration
â”‚   â”‚   â””â”€â”€ api/cron/      # Cron endpoint
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ui/            # Base UI components
â”‚   â”‚   â”œâ”€â”€ charts/        # Data visualization
â”‚   â”‚   â””â”€â”€ layout/        # Layout components
â”‚   â””â”€â”€ lib/
â”‚       â””â”€â”€ utils.ts       # Utility functions
â”œâ”€â”€ .env.local             # Environment variables
â”œâ”€â”€ vercel.json            # Vercel config with cron
â””â”€â”€ package.json
```

## Apify Actors Used

| Platform | Actor | Purpose |
|----------|-------|---------|
| Instagram | `apify/instagram-scraper` | Profile + posts |
| Instagram | `apify/instagram-comment-scraper` | Comments |
| TikTok | `clockworks/tiktok-scraper` | Profile + videos |
| YouTube | `streamers/youtube-scraper` | Channel + videos |

## Database Schema

- **markets** - Geographic markets
- **accounts** - Competitor accounts to track
- **accountSnapshots** - Daily follower/following counts
- **posts** - Individual posts/videos
- **postSnapshots** - Daily engagement metrics
- **comments** - Post comments
- **engagers** - Users who liked/commented
- **contentAnalysis** - AI-generated content analysis
- **scrapingJobs** - Job tracking
- **insights** - Aggregated analytics

## Daily Cron Job

The cron job runs daily at 6:00 AM UTC and:
1. Checks all accounts for pending scrapes
2. Triggers Apify actors for each platform
3. Processes and stores results
4. Updates engagement snapshots

## License

MIT
